# Multimodal Biometric Authentication Using Lip Motion and Spoken Passphrases  
### BIOVID Challenge 2025 â€“ Dual-Factor Audioâ€“Visual Authentication  

**Authors:**  
- **Venu Siddapura Govindaraju** â€“ University of Naples Federico II, DIETI  
- **Stefano Marrone** â€“ University of Naples Federico II, DIETI  
- **Carlo Sansone** â€“ University of Naples Federico II, DIETI  

This repository contains the official implementation of our method submitted to the **BIOVID Challenge 2025**, titled:

> **â€œMultimodal Biometric Authentication Using Lip Motion and Spoken Passphrases.â€**  
> (Accepted in ICIAP 2025 Workshop â€“ BIOVID Challenge, LNCS Volume)

The system performs **open-set biometric authentication** using synchronized audioâ€“visual MP4 videos. Each authentication sample includes:

- **Lip-motion RGB frames**  
- **Spoken passphrase audio**

We design a **dual-stream deep learning architecture** using a 3D-ResNet18 + BiGRU visual encoder and an ECAPA-TDNN audio encoder. These embeddings are fused using a **Gated Multimodal Unit (GMU)** to produce a 256-dimensional joint embedding for both **classification** and **identity verification**.

---

## ğŸ”¥ Key Contributions

- **Dual-stream architecture:**  
  - 3D-ResNet-18 + BiGRU (visual)  
  - ECAPA-TDNN (audio)  
- **Gated Multimodal Unit (GMU)** for adaptive, learned fusion  
- **Hybrid loss function** using Triplet Loss + Binary Cross Entropy  
- **Open-set verification** using cosine similarity + thresholding  
- Reproducible training, evaluation, and submission-generation pipeline  

---

## ğŸ§  System Architecture

Include your architecture figure here:

```markdown
![Architecture](architecture.jpg)


---

# ğŸ“‚ Project Structure

```text
Biovid-Challenge2025/
â”œâ”€â”€ data/                     # EXCLUDED â€“ confidential BIOVID dataset
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ biovid_dataset.py     # Video/audio reader + preprocessing
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ audio_encoder.py      # ECAPA-TDNN backbone
â”‚   â”œâ”€â”€ visual_encoder.py     # 3D-ResNet18 + BiGRU
â”‚   â”œâ”€â”€ gmu_fusion.py         # Gated Multimodal Unit
â”‚   â”œâ”€â”€ fusion_head.py
â”‚   â””â”€â”€ output_head.py
â”‚
â”œâ”€â”€ samplers/
â”‚   â””â”€â”€ triplet_sampler.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ preprocess.py     # Frame extraction, audio extraction
â”‚   â”œâ”€â”€ inference/
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ updated_pipeline.ipynb
â”‚   â””â”€â”€ 02_model_visual.ipynb
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ fold0_best_model.pt
â”‚   â”œâ”€â”€ fold1_best_model.pt
â”‚   â”œâ”€â”€ fold2_best_model.pt
â”‚   â””â”€â”€ gmu_fusion/
â”‚       â””â”€â”€ fold0_best_model.pt
â”‚
â”œâ”€â”€ submission/
â”‚   â””â”€â”€ submission.json
â”‚
â”œâ”€â”€ train_crossval.py
â”œâ”€â”€ test_inference_vote.py
â”œâ”€â”€ evaluate_eer.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## ğŸ”§ Preprocessing

Each MP4 sample is processed into:

- **30 RGB frames** (96Ã—96)  
- **16 kHz mono audio waveform**  

Run preprocessing:

```bash
python scripts/preprocessing/preprocess.py \
    --input data/raw \
    --output data/processed


## Dataset (BIOVID Challenge 2025)

The BIOVID dataset is restricted and cannot be shared publicly.

To access it:

        Register for the BIOVID Challenge 2025

        Submit your method description

        Receive download approval from organizers

## Results
3-Fold Cross-Validation (Validation Set)
| Fold        | Accuracy   | EER        | APCER      | BPCER      |
| ----------- | ---------- | ---------- | ---------- | ---------- |
| 0           | 72.48%     | 27.53%     | 27.47%     | 27.58%     |
| 1           | 68.46%     | 31.57%     | 31.39%     | 31.75%     |
| 2           | 73.15%     | 26.74%     | 27.17%     | 26.31%     |
| **Average** | **71.36%** | **28.61%** | **28.68%** | **28.55%** |


##BIOVID Hidden Test Set

        71.00% accuracy

        33 accepted predictions

        92 rejected as â€œunknownâ€