{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHTRvUHeaVbWb+pnrs4hqj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Example Usage\n","Let’s test it on one preprocessed file:"],"metadata":{"id":"Mv18DdqwYbze"}},{"cell_type":"code","source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\")\n"],"metadata":{"id":"z17P5nR_Yt3_","executionInfo":{"status":"ok","timestamp":1750356649413,"user_tz":-330,"elapsed":43,"user":{"displayName":"Venu Siddapura Govindaraju","userId":"05712073515251967301"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"AP_n5WXaYALe","executionInfo":{"status":"error","timestamp":1750356861443,"user_tz":-330,"elapsed":29,"user":{"displayName":"Venu Siddapura Govindaraju","userId":"05712073515251967301"}},"outputId":"1d174cb9-3370-4795-a998-5bc357de8446"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'models'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-7-3743149793.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# ✅ Import model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_encoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisualEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import torch\n","import sys\n","\n","# ✅ Add model path\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\")\n","\n","# ✅ Import model\n","from models.visual_encoder import VisualEncoder\n","\n","\n","\n"]},{"cell_type":"code","source":["\n","import numpy as np\n","import torch\n","\n","frames = np.load(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/train/10_00_T/frames.npy\")\n","frames_tensor = torch.tensor(frames).unsqueeze(0).float()  # [1, 3, 30, 96, 96]\n","\n","model = VisualEncoder()\n","model.eval()\n","with torch.no_grad():\n","    output = model(frames_tensor)\n","\n","print(\"Visual embedding shape:\", output.shape)  # [1, 256]\n"],"metadata":{"id":"ZWnQL3RLYek3"},"execution_count":null,"outputs":[]}]}