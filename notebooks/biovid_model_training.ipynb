{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120062,
     "status": "ok",
     "timestamp": 1757650332064,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -120
    },
    "id": "7dJKs9g3SGOu",
    "outputId": "05e08f2c-28b7-4e42-feff-ccffd01265cb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1750399647581,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "N7bv47IESTOk",
    "outputId": "755c24bf-593e-4ee1-9488-f7ee5b7fcbf3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define base directory\n",
    "base_dir = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\"\n",
    "\n",
    "# Folder structure\n",
    "folders = [\n",
    "    \"data\",\n",
    "    \"data/processed\",\n",
    "    \"data/splits\",\n",
    "    \"models\",\n",
    "    \"results\",\n",
    "    \"scripts\",\n",
    "    \"scripts/preprocessing\",\n",
    "    \"scripts/training\",\n",
    "    \"scripts/inference\",\n",
    "    \"scripts/utils\",\n",
    "    \"notebooks\"\n",
    "]\n",
    "\n",
    "# Create folders\n",
    "for folder in folders:\n",
    "    path = os.path.join(base_dir, folder)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2149,
     "status": "ok",
     "timestamp": 1750399653827,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "ROrTsNp8SwpM",
    "outputId": "2b701573-5847-40ea-a5af-58896a0bc329"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"/content/drive/MyDrive/biovid_dual_auth/dataset/train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5952,
     "status": "ok",
     "timestamp": 1750399667465,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "SwtIY-t_UjZp",
    "outputId": "68fe85e7-cb13-4080-f127-82c199753e35"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless librosa ffmpeg-python numpy tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bC9Hkqn8TCT6"
   },
   "source": [
    "**Preprocessing Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0jFeb4GS041"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import librosa\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_audio(video_path, output_wav, sr=16000):\n",
    "    y, _ = librosa.load(video_path, sr=sr, mono=True)\n",
    "    librosa.output.write_wav(output_wav, y, sr)\n",
    "\n",
    "def extract_frames(video_path, output_npy, num_frames=30, size=(96, 96)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_idxs = np.linspace(0, total_frames - 1, num=num_frames, dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        if idx in frame_idxs:\n",
    "            frame = cv2.resize(frame, size)\n",
    "            frame = frame[..., ::-1]  # BGR to RGB\n",
    "            frame = frame / 255.0  # normalize\n",
    "            frames.append(frame.transpose(2, 0, 1))  # CxHxW\n",
    "\n",
    "    cap.release()\n",
    "    frames = np.stack(frames, axis=0)  # [30, 3, 96, 96]\n",
    "    frames = frames.transpose(1, 0, 2, 3)  # [3, 30, 96, 96]\n",
    "    np.save(output_npy, frames)\n",
    "\n",
    "def preprocess_folder(input_folder, output_folder):\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    video_files = list(Path(input_folder).rglob(\"*.mp4\"))\n",
    "\n",
    "    for video_path in tqdm(video_files):\n",
    "        uid = video_path.stem\n",
    "        out_video_dir = Path(output_folder) / uid\n",
    "        out_video_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        frames_path = out_video_dir / \"frames.npy\"\n",
    "        audio_path = out_video_dir / \"audio.wav\"\n",
    "\n",
    "        try:\n",
    "            extract_frames(str(video_path), str(frames_path))\n",
    "            extract_audio(str(video_path), str(audio_path))\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {video_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlx1D9DxTGkO"
   },
   "source": [
    "These Paths in Colab Before Running Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 826986,
     "status": "ok",
     "timestamp": 1750400504102,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "AJnAMlTqS9XT",
    "outputId": "2f5f0f25-1b65-47bf-ccb0-82df38429cfb"
   },
   "outputs": [],
   "source": [
    "train_input = \"/content/drive/MyDrive/biovid_dual_auth/dataset/train\"\n",
    "test_input = \"/content/drive/MyDrive/biovid_dual_auth/dataset/test-set\"\n",
    "\n",
    "train_output = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/train\"\n",
    "test_output  = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/test\"\n",
    "\n",
    "preprocess_folder(train_input, train_output)\n",
    "preprocess_folder(test_input, test_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166640,
     "status": "ok",
     "timestamp": 1750400742422,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "Nly3RUJ2AG2E",
    "outputId": "9d733232-54f8-4ed6-b705-b5e937cab04b"
   },
   "outputs": [],
   "source": [
    "train_input = \"/content/drive/MyDrive/biovid_dual_auth/dataset/train\"\n",
    "test_input = \"/content/drive/MyDrive/biovid_dual_auth/dataset/test-set\"\n",
    "\n",
    "train_output = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/train\"\n",
    "test_output  = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/test\"\n",
    "\n",
    "preprocess_folder(train_input, train_output)\n",
    "preprocess_folder(test_input, test_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1750400877184,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "yOTxoo-qBRu-",
    "outputId": "73260956-dbc8-4068-e370-3fab8470a500"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "processed_path = \"/content/drive/MyDrive/biovid_dual_auth/data/processed/train\"\n",
    "print(\"Sample folders found:\")\n",
    "print(os.listdir(processed_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1750400952921,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "KEIEGH0wBj6j",
    "outputId": "ce0254f3-0786-4f40-a8e9-5eb7f25b8ecb"
   },
   "outputs": [],
   "source": [
    "frames_path = f\"/content/drive/MyDrive/biovid_dual_auth/data/processed/train/5_01_T/frames.npy\"\n",
    "frames = np.load(frames_path)\n",
    "print(\"Shape of frames:\", frames.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1750400990880,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "mXvx21KgBzH5",
    "outputId": "0677f6d3-867a-455c-adeb-d501754f9877"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_npy = glob.glob(\"/content/drive/MyDrive/biovid_dual_auth/data/processed/train/5_01_T/frames.npy\", recursive=True)\n",
    "print(\"Total .npy files found:\", len(all_npy))\n",
    "print(\"Example path:\", all_npy[0] if all_npy else \"None found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHfubRnsDjQX"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def extract_audio(video_path, output_wav, sr=16000):\n",
    "    # Step 1: extract raw audio from video using ffmpeg\n",
    "    tmp_wav = \"temp.wav\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", video_path,\n",
    "        \"-ar\", str(sr),\n",
    "        \"-ac\", \"1\",\n",
    "        \"-y\", tmp_wav\n",
    "    ]\n",
    "    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    # Step 2: load with librosa to ensure it's in correct shape\n",
    "    y, _ = librosa.load(tmp_wav, sr=sr)\n",
    "    sf.write(output_wav, y, sr)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(tmp_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2193,
     "status": "ok",
     "timestamp": 1750401623660,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "bfN0pLiDEQ0y",
    "outputId": "a4ece632-dc5f-442e-bdc2-7f61ae6c8c6d"
   },
   "outputs": [],
   "source": [
    "from models.audio_encoder import AudioEncoder\n",
    "\n",
    "audio_path = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/train/10_00_T/audio.wav\"\n",
    "audio_encoder = AudioEncoder()\n",
    "embedding = audio_encoder(audio_path)\n",
    "print(\"Audio embedding shape:\", embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shWvVkrGFw4K"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118944,
     "status": "ok",
     "timestamp": 1750401560442,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "4u_c90onDldH",
    "outputId": "d5f6fa73-269d-4718-c073-3a0e90e5e508"
   },
   "outputs": [],
   "source": [
    "train_input = \"/content/drive/MyDrive/biovid_dual_auth/dataset/train\"\n",
    "train_output = \"/content/drive/MyDrive/biovid_dual_auth/data/processed/train\"\n",
    "\n",
    "preprocess_folder(train_input, train_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71327,
     "status": "ok",
     "timestamp": 1750400575438,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "cxaMfvYGTMKG",
    "outputId": "fe9eada0-5cce-4af4-e956-ca6065fc70a3"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmvLU6G0XYFF"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ERzvDPXZ466"
   },
   "outputs": [],
   "source": [
    "from models.visual_encoder import VisualEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1776,
     "status": "ok",
     "timestamp": 1750401187696,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "Z6JLZSU0Z7nG",
    "outputId": "a5247b40-226d-4974-ed85-9bc9d732ab2e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from models.visual_encoder import VisualEncoder\n",
    "\n",
    "# Load a sample frames.npy\n",
    "frames_path = \"/content/drive/MyDrive/biovid_dual_auth/data/processed/train/5_01_T/frames.npy\"\n",
    "frames = np.load(frames_path)\n",
    "frames_tensor = torch.tensor(frames, dtype=torch.float32).unsqueeze(0)  # [1, 3, 30, 96, 96]\n",
    "\n",
    "# Run through model\n",
    "model = VisualEncoder()\n",
    "embedding = model(frames_tensor)  # Output: [1, 256]\n",
    "print(\"Visual embedding shape:\", embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvvZqrHHC4AX"
   },
   "source": [
    "#  Audio Encoder â€“ ECAPA-TDNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLFXaKGJaQiU"
   },
   "source": [
    "Audio Encoder Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqPNCGMOaS4P"
   },
   "source": [
    "Extract 192-dimensional speaker embeddings from each audio.wav file using a pretrained ECAPA-TDNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK09kPqyaU4C"
   },
   "source": [
    "| Component     | Description                                          |\n",
    "| ------------- | ---------------------------------------------------- |\n",
    "| **Framework** | [`speechbrain`](https://speechbrain.readthedocs.io/) |\n",
    "| **Model**     | `ECAPA-TDNN` pretrained on VoxCeleb2                 |\n",
    "| **Input**     | `.wav` audio (16 kHz mono)                           |\n",
    "| **Output**    | `[192]` speaker embedding                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ7tymC-aX2x"
   },
   "source": [
    " Install SpeechBrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5907,
     "status": "ok",
     "timestamp": 1750401272166,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "IVxfrpXTaB6r",
    "outputId": "800dd8f9-a0fc-4c30-9d59-64ed494c40f3"
   },
   "outputs": [],
   "source": [
    "!pip install speechbrain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr_w-5A7apb0"
   },
   "source": [
    "Use the Audio Encoder in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1750402093544,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "5aQHtvTCDWmM",
    "outputId": "41249f67-1249-4ae4-f42c-5f714acaed47"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_audio = glob.glob(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/train/10_00_T/audio.wav\", recursive=True)\n",
    "print(f\"Total audio files found: {len(all_audio)}\")\n",
    "print(\"Example file:\", all_audio[0] if all_audio else \"None found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hO-FD5gLa4Gm"
   },
   "source": [
    "Gated Multimodal Unit (GMU) Fusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1750402223340,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "izMWQ5N4GkB1",
    "outputId": "01b35251-2254-4558-9416-0197f78b2b79"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "visual_encoder = VisualEncoder().to(device)\n",
    "fusion_model = GMUFusion().to(device)\n",
    "audio_encoder = AudioEncoder(device=device)\n",
    "\n",
    "frames_tensor = frames_tensor.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    v_emb = visual_encoder(frames_tensor)\n",
    "    a_emb = audio_encoder(audio_path)\n",
    "    a_emb = a_emb.to(device)  # move audio embedding to same device\n",
    "    score, joint_emb = fusion_model(a_emb, v_emb)\n",
    "\n",
    "print(\"Score:\", score.item())\n",
    "print(\"Joint Embedding Shape:\", joint_emb.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErnVvGXfGHJd"
   },
   "source": [
    "#  Fusion + Output Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1750402271457,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "ne3EenDhGQIz",
    "outputId": "83577c57-2859-4ab2-f30b-7b05da87a38c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from models.visual_encoder import VisualEncoder\n",
    "from models.audio_encoder import AudioEncoder\n",
    "from models.fusion_head import GMUFusion\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load models on correct device\n",
    "visual_encoder = VisualEncoder().to(device)\n",
    "fusion_model = GMUFusion().to(device)\n",
    "audio_encoder = AudioEncoder(device=device)  # SpeechBrain uses its own device\n",
    "\n",
    "# Load input\n",
    "frames_path = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/train/10_00_T/frames.npy\"\n",
    "audio_path = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/data/processed/train/10_00_T/audio.wav\"\n",
    "\n",
    "frames = np.load(frames_path)\n",
    "frames_tensor = torch.tensor(frames, dtype=torch.float32).unsqueeze(0).to(device)  # [1, 3, 30, 96, 96]\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    v_emb = visual_encoder(frames_tensor)  # [1, 256]\n",
    "    a_emb = audio_encoder(audio_path)      # [1, 192]\n",
    "    a_emb = a_emb.to(device)               # Ensure same device\n",
    "    score, joint_emb = fusion_model(a_emb, v_emb)\n",
    "\n",
    "print(\"âœ… Score:\", score.item())\n",
    "print(\"âœ… Joint Embedding Shape:\", joint_emb.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkr40c6fa6DJ"
   },
   "source": [
    "ðŸŽ¯ Goal:\n",
    "Fuse the 256-dim visual embedding and 192-dim audio embedding into a single 256-dim joint representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jsPc1uea8F2"
   },
   "source": [
    "GMU Fusion Module Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTcq0-y5a_-1"
   },
   "source": [
    "Equation:\n",
    "Let:\n",
    "\n",
    "v = visual embedding [256]\n",
    "a = audio embedding [192]\n",
    "We first project a â†’ 256, then compute:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BId5-HJUbBmz"
   },
   "source": [
    "z = sigmoid(Wz_v * v + Wz_a * a)\n",
    "h = z âŠ™ tanh(Wv * v) + (1 - z) âŠ™ tanh(Wa * a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7R5d76WbLcS"
   },
   "source": [
    "Test in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBagcfAKJckm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1519087,
     "status": "ok",
     "timestamp": 1750405106897,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "UANWEP0BJdOn",
    "outputId": "9d75678b-945e-453a-ec22-cb3a6bbc4adf"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/biovid_dual_auth/updated_pipeline/train_crossval.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG_uptk5TKfo"
   },
   "source": [
    "testset inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79135,
     "status": "ok",
     "timestamp": 1750408221252,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "WxDQII3TTKKS",
    "outputId": "7c83e3a8-1ce5-4a5e-8922-fd7398d7a39f"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/biovid_dual_auth/updated_pipeline/test_inference_vote.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750407097363,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "4opi-IhlZJvc",
    "outputId": "e14446b5-8b97-4384-e503-2482949dd4ed"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.exists(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/submission/submission.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1750357302707,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "dQUz8Xg3aq8x",
    "outputId": "83ad37e1-9b6d-4b08-d9be-8ad1537b58e3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\")\n",
    "from models.gmu_fusion import GMUFusion\n",
    "\n",
    "# Dummy embeddings\n",
    "v = torch.randn(1, 256)  # visual\n",
    "a = torch.randn(1, 192)  # audio\n",
    "\n",
    "fuser = GMUFusion()\n",
    "fused = fuser(v, a)\n",
    "\n",
    "print(\"Fused embedding shape:\", fused.shape)  # [1, 256]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2B2FnLPbYFt"
   },
   "source": [
    "Output Head (Classification + Embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tHWmwambbYG"
   },
   "source": [
    "Build a head that:\n",
    "\n",
    "Outputs a binary prediction (genuine vs impostor)\n",
    "Produces a normalized 256-dim embedding for triplet loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFKsPGvgcFn3"
   },
   "source": [
    "Test the Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1750357538671,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "j7YYEzvFbNuL",
    "outputId": "f478843e-9a9c-459a-d5b4-11a36b0d3003"
   },
   "outputs": [],
   "source": [
    "from models.output_head import OutputHead\n",
    "\n",
    "head = OutputHead()\n",
    "x = torch.randn(4, 256)  # batch of 4 fused embeddings\n",
    "logits, emb = head(x)\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)      # [4, 2]\n",
    "print(\"Embedding shape:\", emb.shape)      # [4, 256]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWJDjx6Qdh6g"
   },
   "source": [
    "Create 3-Fold Splits Without Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3EZORoCcHXY"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from pathlib import Path\n",
    "\n",
    "def create_3fold_user_split(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    all_dirs = list(root.glob(\"*_*_*\"))  # each video folder\n",
    "    all_users = sorted(set([p.name.split(\"_\")[0] for p in all_dirs]))\n",
    "\n",
    "    user_to_label = {u: i for i, u in enumerate(all_users)}\n",
    "    folds = []\n",
    "\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    for train_idx, val_idx in kf.split(all_users):\n",
    "        train_users = set([all_users[i] for i in train_idx])\n",
    "        val_users = set([all_users[i] for i in val_idx])\n",
    "\n",
    "        train_videos = [str(p) for p in all_dirs if p.name.split(\"_\")[0] in train_users]\n",
    "        val_videos = [str(p) for p in all_dirs if p.name.split(\"_\")[0] in val_users]\n",
    "\n",
    "        folds.append((train_videos, val_videos))\n",
    "\n",
    "    return folds, user_to_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8143,
     "status": "ok",
     "timestamp": 1750358231348,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "-LdFS5QLdkMg",
    "outputId": "2e3b34e5-3b69-4bd5-fe45-d5a2a9fb1c95"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/biovid_dual_auth/updated_pipeline/train_crossval.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcKbeFNwgNvr"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1750358648277,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "Npq4DvxNgRx0",
    "outputId": "8672e3c4-e401-4d47-e222-0df132e26833"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Folder contents:\")\n",
    "print(os.listdir(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\"))\n",
    "\n",
    "print(\"\\nDatasets folder contents:\")\n",
    "print(os.listdir(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/datasets\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QaO3uCqgWRa"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1750358876615,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "oNGUqylxhCrj",
    "outputId": "e5c0aa2f-2b2b-4898-97d3-a4b8e7686d5e"
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "# Point to the full path of your biovid_dataset.py file\n",
    "file_path = \"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/datasets/biovid_dataset.py\"\n",
    "\n",
    "# Load as a module\n",
    "spec = importlib.util.spec_from_file_location(\"biovid_dataset\", file_path)\n",
    "biovid = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(biovid)\n",
    "\n",
    "# Now access the classes/functions\n",
    "BiovidDataset = biovid.BiovidDataset\n",
    "create_3fold_user_split = biovid.create_3fold_user_split\n",
    "\n",
    "print(\"âœ… Import successful via importlib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5738,
     "status": "ok",
     "timestamp": 1750365140485,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "UbSGdRrxqO65",
    "outputId": "9057d99c-12fe-44d2-d1a9-f5fec93896eb"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/biovid_dual_auth/updated_pipeline/train_crossval.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37671,
     "status": "ok",
     "timestamp": 1750363820179,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "2nbX8NiSrd-i",
    "outputId": "159f1bf2-7696-41b0-f01b-051e7e4ebde4"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/biovid_dual_auth/updated_pipeline/evaluate_eer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30217,
     "status": "ok",
     "timestamp": 1750365179649,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "DFlvCZ55xbwV",
    "outputId": "e2e4fd07-3349-4938-e80e-538e7b0ee2c5"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/biovid_dual_auth/updated_pipeline/test_inference_vote.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10049,
     "status": "ok",
     "timestamp": 1751190905581,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "NXKBptWAG1LT",
    "outputId": "3c35b4bc-ea7a-45a3-dd8a-4fb4c7ef7dc6"
   },
   "outputs": [],
   "source": [
    "!pip install pydot\n",
    "!apt-get install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1751191194988,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "aTfmBgktG-JO",
    "outputId": "5ba2525c-b6b0-4d40-9f65-50b58dcee064"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import (Input, Conv2D, TimeDistributed, GlobalAveragePooling2D,\n",
    "                          Bidirectional, GRU, Dense, Concatenate, Lambda, Multiply, Add)\n",
    "from keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- Visual Stream (per-frame Conv2D + GRU) ---\n",
    "video_input = Input(shape=(30, 96, 96, 3), name='video_input')\n",
    "x = TimeDistributed(Conv2D(32, (3, 3), padding='same', activation='relu'))(video_input)\n",
    "x = TimeDistributed(GlobalAveragePooling2D())(x)\n",
    "x = Bidirectional(GRU(128))(x)\n",
    "visual_embedding = Dense(256, activation='relu', name='visual_fc')(x)\n",
    "\n",
    "# --- Audio Stream ---\n",
    "audio_input = Input(shape=(192,), name='audio_input')\n",
    "audio_proj = Dense(256, activation='relu', name='audio_fc')(audio_input)\n",
    "\n",
    "# --- GMU Fusion ---\n",
    "concat = Concatenate(name='concat_audio_visual')([visual_embedding, audio_input])\n",
    "z = Dense(256, activation='sigmoid', name='z_gate')(concat)\n",
    "\n",
    "v_trans = Dense(256, activation='tanh', name='v_transform')(visual_embedding)\n",
    "a_trans = Dense(256, activation='tanh', name='a_transform')(audio_proj)\n",
    "\n",
    "z_inv = Lambda(lambda x: 1.0 - x, name='1_minus_z')(z)\n",
    "zv = Multiply(name='zv')([z, v_trans])\n",
    "za = Multiply(name='1mz_a')([z_inv, a_trans])\n",
    "fused = Add(name='gmu_output')([zv, za])\n",
    "\n",
    "# --- Output Head ---\n",
    "classification_output = Dense(1, activation='sigmoid', name='classification')(fused)\n",
    "triplet_embedding = Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name='triplet_norm')(fused)\n",
    "\n",
    "model = Model(inputs=[video_input, audio_input], outputs=[classification_output, triplet_embedding])\n",
    "\n",
    "# Save the model diagram\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file=\"biovid_model.png\", dpi=96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1751191668472,
     "user": {
      "displayName": "Venu Siddapura Govindaraju",
      "userId": "05712073515251967301"
     },
     "user_tz": -330
    },
    "id": "zBvJwiwTJgsg",
    "outputId": "ef8f0725-1293-474d-c849-56a5fce19a59"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/biovid_dual_auth/updated_pipeline/results/biovid_results_20250620_0738.csv\")  # use your actual path\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['fold'], df['accuracy'], label='Accuracy')\n",
    "plt.plot(df['fold'], df['eer'], label='EER')\n",
    "plt.plot(df['fold'], df['apcer'], label='APCER')\n",
    "plt.plot(df['fold'], df['bpcer'], label='BPCER')\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.title(\"Performance Across 3-Fold Cross-Validation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"training_metrics_curve.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-6vaZGfKBWT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzYolrBEYK523Jw58LAkYk",
   "machine_shape": "hm",
   "mount_file_id": "18EGI9RyFUSMYi99MnrGrTVlVAs1Nz9NV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
